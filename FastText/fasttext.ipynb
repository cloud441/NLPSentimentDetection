{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9814cc89",
   "metadata": {},
   "source": [
    "# FastText and Word Vector (TP n°3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a85323ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "import spacy\n",
    "import fasttext as fast\n",
    "import transformers\n",
    "\n",
    "# set a defined random generator, better for reproducible results.\n",
    "random = np.random.default_rng(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49829ed2",
   "metadata": {},
   "source": [
    "## Take a look on IMDB dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3efb039",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset imdb (/home/cloud441/.cache/huggingface/datasets/imdb/plain_text/1.0.0/e3c66f1788a67a89c7058d97ff62b6c30531e05b549de56d3ab91891f0561f9a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3413cc14eb484285ad6162d786f175b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 25000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 25000\n",
      "    })\n",
      "    unsupervised: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 50000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "imdb = load_dataset('imdb')\n",
    "print(imdb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87525b57",
   "metadata": {},
   "source": [
    "And we have the following number of entries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d2e6ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train entries: 25000\n",
      "test entries: 25000\n"
     ]
    }
   ],
   "source": [
    "print(f\"train entries: {len(imdb['train'])}\\ntest entries: {len(imdb['test'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f04a2f",
   "metadata": {},
   "source": [
    "## Translate dataset for FastText API:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1254f12f",
   "metadata": {},
   "source": [
    "Generate a shuffle index list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "198a8c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2187 22262  4672 12858 23855 19338 23333  2842 20483 23441]\n"
     ]
    }
   ],
   "source": [
    "rand_idx = np.arange(len(imdb['train']))\n",
    "np.random.shuffle(rand_idx)\n",
    "print(rand_idx[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f92ab7",
   "metadata": {},
   "source": [
    "Write IMDB dataset into file with FastText format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdaf3212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 399 µs, sys: 269 µs, total: 668 µs\n",
      "Wall time: 628 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if not os.path.exists(\"imdb_train.txt\"):\n",
    "    with open(\"imdb_train.txt\", \"wb\") as f:\n",
    "        for i in rand_idx:\n",
    "            entry = imdb['train'][int(i)]\n",
    "            s = f\"__label__{entry['label']} {entry['text']}\\n\".encode(\"utf-8\")\n",
    "            f.write(s)\n",
    "    \n",
    "        f.close()\n",
    "        \n",
    "# We shuffle rand_idx to apply with test dataset ...\n",
    "np.random.shuffle(rand_idx)\n",
    "        \n",
    "if not os.path.exists(\"imdb_test.txt\"):\n",
    "    with open(\"imdb_test.txt\", \"wb\") as f:\n",
    "        for i in rand_idx:\n",
    "            entry = imdb['test'][int(i)]\n",
    "            s = f\"__label__{entry['label']} {entry['text']}\\n\".encode(\"utf-8\")\n",
    "            f.write(s)\n",
    "    \n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d4c36c",
   "metadata": {},
   "source": [
    "Let's see the input format of an entry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d322b72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__label__0 People who actually liked Problem Child (1990) need to have their heads examined. Who would take the idea of watching a malevolent little boy wreak havoc on others and deem it funny? The movie is not funny, ever, in any way, beginning to end. It wants to be a cartoon, but the writers don't realize that slapstick isn't funny when people get attacked by bears, or hit with baseball bats. It may be funny in cartoons, but not in a motion picture.<br /><br />The film's young hero is Junior (Michael Oliver) who, since he was a baby, has been placed at the front doors of foster parents for adoption. The families reject him, because Junior tends to give them a hard time.<br /><br />He is then thrown into an orphanage, where he terrorizes the nuns, and writes pen pal letters to the convicted Bow-Tie Killer (Michael Richards). He is soon adopted by Ben and Flo Healy (the late John Ritter and his wife, Amy Yasbeck), who are dying to have a child, in order to be just like every other parent in their neighborhood.<br /><br />Junior becomes a member of the Healy household, and \"Little\" Ben takes an interest in him, despite the fact that he destroys a camping trip by luring a bear onto the site, or throws a cat at his father \"Big\" Ben (Jack Warden), a bigoted politician.<br /><br />I think that we're supposed to care for Junior so that we can root for him when he gets his revenge on people. His new mother, Flo, is a bitch, his grandfather is completely selfish, and one little girl--who despises adopted kids--is such a spoiled brat.<br /><br />But what Junior does to get the last laughs isn't funny- -it's mean, cruel, and sometimes life-threatening.<br /><br />And what is the film's message? That kids should resolve problems with violence and vandalism? That they should seek friendship by writing to convicted killers? They definitely don't what it's like to be a bad kid. Junior isn't a one--he's just a sadistic, little twerp. There used to be a time when it was bad for kids to beat up others. Now, everybody's laughing when Junior beats up kids with a baseball bat.<br /><br />It's a shame that this movie has been marketed as a \"family comedy.\" What's worse is that Problem Child is rated PG. What was the MPAA thinking when they saw this? There's a lot of profanity and mean-spirited pranks here, that one may wonder about the dividing between the PG and the PG-13.<br /><br />Kids will enjoy this, but parents will be shocked at what is being depicted on screen. And to most people, Problem Child will be considered a \"guilty pleasure\" classic; a film that someone will shamefacedly admit to liking, even though the prevailing opinion, as put forth by more serious viewers, is that the movie is a piece of crap.\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 1 imdb_train.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f8d696",
   "metadata": {},
   "source": [
    "## First training with FastText model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ac30e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 5M words\n",
      "Number of words:  281132\n",
      "Number of labels: 2\n",
      "Progress: 100.0% words/sec/thread: 3338162 lr:  0.000000 avg.loss:  0.425961 ETA:   0h 0m 0s 0m 0s\n"
     ]
    }
   ],
   "source": [
    "fast_model = fast.train_supervised('imdb_train.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131052e8",
   "metadata": {},
   "source": [
    "Let's see the train vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ed80c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the vocabulary size is: 281132\n",
      "\n",
      "This is a slice of it:\n",
      "['the', 'a', 'and', 'of', 'to', 'is', 'in', 'I', 'that', 'this', 'it', '/><br', 'was', 'as', 'with', 'for', 'but', 'The', 'on', 'movie']\n"
     ]
    }
   ],
   "source": [
    "print(f\"the vocabulary size is: {len(fast_model.words)}\\n\\nThis is a slice of it:\\n{fast_model.words[:20]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6fe6b2",
   "metadata": {},
   "source": [
    "### Results of the model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f10eb9",
   "metadata": {},
   "source": [
    "We respectfully copy and paste this print function from FastText documentation to see results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1373799",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(N : int, p : float, r : float) -> None:\n",
    "    print(\"N\\t\" + str(N))\n",
    "    print(\"P@{}\\t{:.3f}\".format(1, p))\n",
    "    print(\"R@{}\\t{:.3f}\".format(1, r))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f8ded3",
   "metadata": {},
   "source": [
    "So let's compute precision at 1 (P@1) and the recall on the test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e202d23e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t25000\n",
      "P@1\t0.860\n",
      "R@1\t0.860\n"
     ]
    }
   ],
   "source": [
    "print_results(*fast_model.test('imdb_test.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892b6996",
   "metadata": {},
   "source": [
    "And we can compute these metrics for all labels separately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d975f76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_labels_results(l_scores : dict[str, dict[str, float]]) -> None:\n",
    "    for label in l_scores:\n",
    "        print(f\"label '{label}':\\n\")\n",
    "        print(f\"\\tprecision: {np.round(l_scores[label]['precision'], 3)}\")\n",
    "        print(f\"\\trecall: {np.round(l_scores[label]['recall'], 3)}\")\n",
    "        print(f\"\\tF1 score: {np.round(l_scores[label]['f1score'], 3)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6d7b27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label '__label__0':\n",
      "\n",
      "\tprecision: 0.86\n",
      "\trecall: nan\n",
      "\tF1 score: 1.72\n",
      "\n",
      "label '__label__1':\n",
      "\n",
      "\tprecision: 0.86\n",
      "\trecall: nan\n",
      "\tF1 score: 1.719\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_labels_results(fast_model.test_label('imdb_test.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae963c3",
   "metadata": {},
   "source": [
    "## Pre-processing on IMDB dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60794076",
   "metadata": {},
   "source": [
    "### Stemming the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ee55bb",
   "metadata": {},
   "source": [
    "### Lemming the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67dfb962",
   "metadata": {},
   "source": [
    "Firstly, we need to download the english model of Spacy lemmatization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50012030",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_sm > output_dl.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5bc8baf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the small English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "152368f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 350 µs, sys: 41 µs, total: 391 µs\n",
      "Wall time: 393 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Shuffle order again\n",
    "np.random.shuffle(rand_idx)\n",
    "\n",
    "if not os.path.exists(\"lemmed_imdb_train.txt\"):\n",
    "    with open(\"lemmed_imdb_train.txt\", \"wb\") as f:\n",
    "        for i in rand_idx:\n",
    "            entry = imdb['train'][int(i)]\n",
    "            \n",
    "            # lemmatize before writting\n",
    "            lemmed_text = ' '.join([token.lemma_ for token in nlp(entry['text'])])\n",
    "            s = f\"__label__{entry['label']} {lemmed_text}\\n\".encode(\"utf-8\")\n",
    "            f.write(s)\n",
    "    \n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb82b8a6",
   "metadata": {},
   "source": [
    "Do it in test dataset also:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22937706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle order again\n",
    "np.random.shuffle(rand_idx)\n",
    "\n",
    "if not os.path.exists(\"lemmed_imdb_test.txt\"):\n",
    "    with open(\"lemmed_imdb_test.txt\", \"wb\") as f:\n",
    "        for i in rand_idx:\n",
    "            entry = imdb['test'][int(i)]\n",
    "            \n",
    "            # lemmatize before writting\n",
    "            lemmed_text = ' '.join([token.lemma_ for token in nlp(entry['text'])])\n",
    "            s = f\"__label__{entry['label']} {lemmed_text}\\n\".encode(\"utf-8\")\n",
    "            f.write(s)\n",
    "    \n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7404829f",
   "metadata": {},
   "source": [
    "## Hyperparameters tunning:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2a357e",
   "metadata": {},
   "source": [
    "We need to extract a validation set of our train dataset to avoid a tunning validation on test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02366b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 cloud441 cloud441 26845142 28 sept. 12:19 ./tuning_aa\r\n",
      "-rw-r--r-- 1 cloud441 cloud441  6587681 28 sept. 12:19 ./tuning_ab\r\n"
     ]
    }
   ],
   "source": [
    "# split command will copy and separate file into set of files of 20000 lines.\n",
    "# Train file have 25.000 lines, so train will have 20.000 lines and validation 5.000 lines.\n",
    "!split -l20000 \"imdb_train.txt\" tuning_\n",
    "\n",
    "!ls -l ./tuning_*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e26d837",
   "metadata": {},
   "source": [
    "### Try the default hyperparameter tunning of FastText:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f315ad8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100.0% Trials:    9 Best score:  0.889420 ETA:   0h 0m 0s\n",
      "Training again with best arguments\n",
      "Read 4M words\n",
      "Number of words:  245418\n",
      "Number of labels: 2\n",
      "Progress: 100.0% words/sec/thread: 1349410 lr:  0.000000 avg.loss:  0.049218 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "tunning_fast_model = fast.train_supervised(input='tuning_aa', autotuneValidationFile='tuning_ab', autotuneMetric=\"f1:__label__0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fcbfef",
   "metadata": {},
   "source": [
    "Let's compute global metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b0845727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t25000\n",
      "P@1\t0.884\n",
      "R@1\t0.884\n"
     ]
    }
   ],
   "source": [
    "print_results(*tunning_fast_model.test('imdb_test.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d8a41a",
   "metadata": {},
   "source": [
    "It looks to give better results with default hyperparameter tunning. But how labels scores change ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65768679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label '__label__0':\n",
      "\n",
      "\tprecision: 0.888\n",
      "\trecall: nan\n",
      "\tF1 score: 1.777\n",
      "\n",
      "label '__label__1':\n",
      "\n",
      "\tprecision: 0.879\n",
      "\trecall: nan\n",
      "\tF1 score: 1.758\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_labels_results(tunning_fast_model.test_label('imdb_test.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8508810",
   "metadata": {},
   "source": [
    "Results are better with tunning and we highlight that optimize f1 result on __negative__ label induces better improvements on __positive__ label. The reason is because we juste have two labels and __negative__ label had less wrongly classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ac6021",
   "metadata": {},
   "source": [
    "## Conclusion:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
