{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5104d738",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-21 16:51:03.692662: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-09-21 16:51:03.692760: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import collections\n",
    "from datasets import load_dataset\n",
    "import datasets\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25c2cc67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset imdb (/home/leherlemaxime/.cache/huggingface/datasets/imdb/plain_text/1.0.0/e3c66f1788a67a89c7058d97ff62b6c30531e05b549de56d3ab91891f0561f9a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81d75bef94a040b793fabf7fb971d688",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "word_index = keras.datasets.imdb.get_word_index()\n",
    "inverted_word_index = dict((i, word) for (word, i) in word_index.items())\n",
    "\n",
    "dataset = datasets.load_dataset('imdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb26885e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"vader_lexicon.txt\", \"r\", encoding=\"utf-8\")\n",
    "lines = file.readlines()\n",
    "file.close()\n",
    "\n",
    "good_lines = []\n",
    "\n",
    "for line in lines:\n",
    "    line_temp = line.replace(\"\\t\", \" \")\n",
    "    line_temp = line_temp.split(\" \")\n",
    "    line_temp = line_temp[:2]\n",
    "    good_lines.append(line_temp)\n",
    "    \n",
    "dict_value = dict(good_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e18e161",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_the_text(text_array):\n",
    "    \n",
    "    specialChars = \"()\\\\\\''.,;:\\\"?-\" \n",
    "    for specialChar in specialChars:\n",
    "        text_array = text_array.replace(specialChar, ' ')\n",
    "        \n",
    "    text_array = text_array.replace(\"/>\", ' ')\n",
    "    text_array = text_array.replace(\"<br\", ' ')\n",
    "    text_array = text_array.replace(\"!\", \" ! \")\n",
    "    \n",
    "    text_array = text_array.split(\" \")\n",
    "    \n",
    "    result_array = [elem.lower() for elem in text_array if(len(elem) != 0)]\n",
    "    \n",
    "    return result_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "781f34f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_to_array(dataset):\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    x_test = []\n",
    "    y_test = []\n",
    "    \n",
    "    for elem in dataset[\"train\"]:\n",
    "        y_train.append(elem[\"label\"])\n",
    "        x_train.append(clean_the_text(elem[\"text\"]))\n",
    "        \n",
    "    for elem in dataset[\"test\"]:\n",
    "        y_test.append(elem[\"label\"])\n",
    "        x_test.append(clean_the_text(elem[\"text\"]))\n",
    "        \n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "969ac921",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = dataset_to_array(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ba379f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_array_to_feature(word_array):\n",
    "    feature = []\n",
    "    \n",
    "    # No feature\n",
    "    \n",
    "    if (\"no\" in word_array):\n",
    "        feature.append(1)\n",
    "    else:\n",
    "        feature.append(0)\n",
    "        \n",
    "    # Pronouns feature\n",
    "    \n",
    "    valid_pronouns = [\"i\", \"me\", \"my\", \"mine\", \"myself\", \"you\", \"your\", \"yours\", \"yourself\", \"we\", \"us\", \"our\", \"ourselves\"]\n",
    "    pronouns_count = 0\n",
    "    for elem in word_array:\n",
    "        if (elem in valid_pronouns):\n",
    "            pronouns_count += 1\n",
    "            \n",
    "    feature.append(pronouns_count)\n",
    "            \n",
    "    # ! feature\n",
    "        \n",
    "    if (\"!\" in word_array):\n",
    "        feature.append(1)\n",
    "    else:\n",
    "        feature.append(0)\n",
    "        \n",
    "    # log(nb_word) feature\n",
    "    \n",
    "    feature.append(math.log(len(word_array)))\n",
    "    \n",
    "    # positive and negative feature\n",
    "    positive_count = 0\n",
    "    negative_count = 0\n",
    "    \n",
    "    for elem in word_array :\n",
    "        if ((elem in dict_value) and (float(dict_value[elem]) >= 1.5)):\n",
    "            positive_count += 1\n",
    "        elif ((elem in dict_value) and (float(dict_value[elem]) <= -1.5)):\n",
    "            negative_count += 1\n",
    "            \n",
    "    feature.append(positive_count)\n",
    "    feature.append(negative_count)\n",
    "    \n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6748ed26",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_feature = [word_array_to_feature(elem) for elem in x_train]\n",
    "x_test_feature = [word_array_to_feature(elem) for elem in x_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c1411441",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "50a322ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=0).fit(x_train_feature, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cb35cde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(x_test_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a8f517a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.71007589, 0.70627874]),\n",
       " array([0.7036 , 0.71272]),\n",
       " array([0.70682311, 0.70948475]),\n",
       " array([12500, 12500]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
