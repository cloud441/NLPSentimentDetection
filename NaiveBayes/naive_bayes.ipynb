{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f4f6229",
   "metadata": {},
   "source": [
    "# Naive Bayes model  (TP nÂ°1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "463ff073",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from typing import Callable\n",
    "from termcolor import colored\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from nltk import tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "''' set a defined random generator, better for reproducible results. '''\n",
    "random = np.random.default_rng(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9efdc2",
   "metadata": {},
   "source": [
    "## Take a look on IMDB dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74d50dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset imdb (/home/cloud441/.cache/huggingface/datasets/imdb/plain_text/1.0.0/e3c66f1788a67a89c7058d97ff62b6c30531e05b549de56d3ab91891f0561f9a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4159740eb04a4447aa69b3dac86c2054",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 25000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 25000\n",
      "    })\n",
      "    unsupervised: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 50000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "imdb = load_dataset('imdb')\n",
    "print(imdb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0258cab",
   "metadata": {},
   "source": [
    "Let's see one example of entry in the IMDB database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "487a4063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as \"Teachers\". My 35 years in the teaching profession lead me to believe that Bromwell High\\'s satire is much closer to reality than is \"Teachers\". The scramble to survive financially, the insightful students who can see right through their pathetic teachers\\' pomp, the pettiness of the whole situation, all remind me of the schools I knew and their students. When I saw the episode in which a student repeatedly tried to burn down the school, I immediately recalled ......... at .......... High. A classic line: INSPECTOR: I\\'m here to sack one of your teachers. STUDENT: Welcome to Bromwell High. I expect that many adults of my age think that Bromwell High is far fetched. What a pity that it isn\\'t!',\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d03f504",
   "metadata": {},
   "source": [
    "And we have the following number of entries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ec1aa61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train entries: 25000\n",
      "test entries: 25000\n"
     ]
    }
   ],
   "source": [
    "print(f\"train entries: {len(imdb['train'])}\\ntest entries: {len(imdb['test'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dda6ae",
   "metadata": {},
   "source": [
    "## Tokenize into a word/label dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "669ec997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bromwell</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>High</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>is</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cartoon</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word  label\n",
       "0  Bromwell      1\n",
       "1      High      1\n",
       "2        is      1\n",
       "3         a      1\n",
       "4   cartoon      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Train split dataset '''\n",
    "train_dataset = []\n",
    "\n",
    "for entry in imdb['train']:\n",
    "    for word in tokenize.word_tokenize(entry['text']):\n",
    "        train_dataset += [[word, entry['label']]]\n",
    "\n",
    "train_dataset = pd.DataFrame(train_dataset, columns=['word', 'label'])\n",
    "\n",
    "''' Let's see the final form: '''\n",
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2de03e67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Test split dataset '''\n",
    "test_dataset = []\n",
    "\n",
    "for entry in imdb['test']:\n",
    "    for word in tokenize.word_tokenize(entry['text']):\n",
    "        test_dataset += [[word, entry['label']]]\n",
    "\n",
    "test_dataset = pd.DataFrame(test_dataset, columns=['word', 'label'])\n",
    "type(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddba4df9",
   "metadata": {},
   "source": [
    "### Build Vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73bb0902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.indexes.base.Index"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = train_dataset['word'].factorize()[1] # pandas does the factorization for us\n",
    "type(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad72fb6",
   "metadata": {},
   "source": [
    "## Build the Naive Bayes model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29346c0",
   "metadata": {},
   "source": [
    "Type aliases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "762ece5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame = pd.core.frame.DataFrame\n",
    "index = pd.core.indexes.base.Index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58000d0d",
   "metadata": {},
   "source": [
    "The Bayes model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50a30110",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [0, 1] # 0 is the class for negatives review and 1 for positives\n",
    "\n",
    "def train_naive_bayes(dataset: DataFrame, classes: list[int], vocabulary: index) -> (list[float], dict[(int, str), float]):\n",
    "    ''' Train a Naive Bayes model using the given dataset and according vocabulary '''\n",
    "    \n",
    "    classes_counter = dataset.groupby('label').count().word\n",
    "    print(f\"classes_counter is:\\n{classes_counter}\")\n",
    "    \n",
    "    loglikehood = {}\n",
    "    logprior = []\n",
    "    \n",
    "    ''' computing each class loglikehood '''\n",
    "    for c in classes:\n",
    "        c_counter = classes_counter[c]\n",
    "        \n",
    "        logprior.append(math.log(c_counter / len(dataset)))\n",
    "       \n",
    "        bag_of_word = dataset[dataset.label == c].word\n",
    "        word_counts = bag_of_word.value_counts()\n",
    "                                                                                     \n",
    "        \n",
    "        ''' compute each word loglikehood by class '''\n",
    "        for word in vocabulary:\n",
    "            count_word_c = word_counts[word] if (word in word_counts) else 0\n",
    "            loglikehood[(c,word)] = math.log((count_word_c + 1)/(len(bag_of_word) + 1))\n",
    "    \n",
    "    return (logprior, loglikehood)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa62603",
   "metadata": {},
   "source": [
    "So, the training of naive Bayes model on train IMDB dataset gives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebc87556",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes_counter is:\n",
      "label\n",
      "0    3505555\n",
      "1    3559778\n",
      "Name: word, dtype: int64\n",
      "CPU times: user 2.35 s, sys: 62.8 ms, total: 2.42 s\n",
      "Wall time: 2.43 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "(logprior, loglikehood) = train_naive_bayes(train_dataset, classes, vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3e89e56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.700851295611307, -0.6855019654147522]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logprior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d658cdf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 'Bromwell'): -15.069859696398153,\n",
       " (0, 'High'): -10.474739846263564,\n",
       " (0, 'is'): -4.2263258236334735,\n",
       " (0, 'a'): -3.8289792031003067,\n",
       " (0, 'cartoon'): -9.486363387616453,\n",
       " (0, 'comedy'): -7.8664541753150585,\n",
       " (0, '.'): -3.3838552560009028,\n",
       " (0, 'It'): -5.9960265690766335,\n",
       " (0, 'ran'): -10.369379330605737,\n",
       " (0, 'at'): -5.733944501513904,\n",
       " (0, 'the'): -3.2222349942130877,\n",
       " (0, 'same'): -7.458511978994532,\n",
       " (0, 'time'): -6.418310452482837,\n",
       " (0, 'as'): -5.215142308231455,\n",
       " (0, 'some'): -6.127791003353928,\n",
       " (0, 'other'): -6.758952939229703,\n",
       " (0, 'programs'): -11.73765518622295,\n",
       " (0, 'about'): -5.9783028604119375,\n",
       " (0, 'school'): -8.455134096194392,\n",
       " (0, 'life'): -7.413995678782096,\n",
       " (0, ','): -3.280735339042627,\n",
       " (0, 'such'): -7.2623496541819605,\n",
       " (0, '``'): -5.318183894451408,\n",
       " (0, 'Teachers'): -13.460421783964053,\n",
       " (0, \"''\"): -5.322499776573505,\n",
       " (0, 'My'): -8.223979821134103,\n",
       " (0, '35'): -11.573352134931673,\n",
       " (0, 'years'): -7.6540827209827595,\n",
       " (0, 'in'): -4.459864611600243,\n",
       " (0, 'teaching'): -11.332190078114785,\n",
       " (0, 'profession'): -11.73765518622295,\n",
       " (0, 'lead'): -8.585224460762902,\n",
       " (0, 'me'): -6.4822080413333545,\n",
       " (0, 'to'): -3.9459257768432003,\n",
       " (0, 'believe'): -7.848023871109704,\n",
       " (0, 'that'): -4.583849308635005,\n",
       " (0, \"'s\"): -4.7628422403883715,\n",
       " (0, 'satire'): -10.282367953616108,\n",
       " (0, 'much'): -6.583125712466624,\n",
       " (0, 'closer'): -10.713150869708562,\n",
       " (0, 'reality'): -9.237977219114637,\n",
       " (0, 'than'): -6.526803845456189,\n",
       " (0, 'The'): -5.068746465077585,\n",
       " (0, 'scramble'): -13.460421783964053,\n",
       " (0, 'survive'): -10.454739179556894,\n",
       " (0, 'financially'): -12.872635119061934,\n",
       " (0, 'insightful'): -11.891805866050207,\n",
       " (0, 'students'): -9.802001537334824,\n",
       " (0, 'who'): -5.909865698858709,\n",
       " (0, 'can'): -6.37301517674384,\n",
       " (0, 'see'): -6.504257365774229,\n",
       " (0, 'right'): -7.760647330705391,\n",
       " (0, 'through'): -7.24901881649081,\n",
       " (0, 'their'): -6.526803845456189,\n",
       " (0, 'pathetic'): -9.150965842125007,\n",
       " (0, 'teachers'): -11.406298050268507,\n",
       " (0, \"'\"): -6.595156556602868,\n",
       " (0, 'pomp'): -13.460421783964053,\n",
       " (0, 'pettiness'): -15.069859696398153,\n",
       " (0, 'of'): -3.9424055540412137,\n",
       " (0, 'whole'): -7.604776959998605,\n",
       " (0, 'situation'): -9.453088598731583,\n",
       " (0, 'all'): -5.797577922881787,\n",
       " (0, 'remind'): -10.765794603193983,\n",
       " (0, 'schools'): -11.604123793598427,\n",
       " (0, 'I'): -4.382973009325053,\n",
       " (0, 'knew'): -8.996815162297748,\n",
       " (0, 'and'): -3.910029874428031,\n",
       " (0, 'When'): -8.079603195904273,\n",
       " (0, 'saw'): -7.8142684221444885,\n",
       " (0, 'episode'): -8.654762737226559,\n",
       " (0, 'which'): -6.440767412484507,\n",
       " (0, 'student'): -9.771542329850117,\n",
       " (0, 'repeatedly'): -10.880204954371727,\n",
       " (0, 'tried'): -8.845301267122792,\n",
       " (0, 'burn'): -10.726054274544468,\n",
       " (0, 'down'): -7.570436405805925,\n",
       " (0, 'immediately'): -9.732321616696835,\n",
       " (0, 'recalled'): -12.990418154718316,\n",
       " (0, '.........'): -12.584953046610153,\n",
       " (0, '..........'): -12.872635119061934,\n",
       " (0, 'A'): -7.123950097785021,\n",
       " (0, 'classic'): -8.681298290852522,\n",
       " (0, 'line'): -8.31060442573446,\n",
       " (0, ':'): -6.511332641488939,\n",
       " (0, 'INSPECTOR'): -14.376712515838207,\n",
       " (0, \"'m\"): -7.1084894946786426,\n",
       " (0, 'here'): -7.220925970034082,\n",
       " (0, 'sack'): -11.934365480469003,\n",
       " (0, 'one'): -5.715418980448214,\n",
       " (0, 'your'): -7.032639665265142,\n",
       " (0, 'STUDENT'): -14.376712515838207,\n",
       " (0, 'Welcome'): -12.179487938501989,\n",
       " (0, 'expect'): -8.69653990682114,\n",
       " (0, 'many'): -7.156338679114258,\n",
       " (0, 'adults'): -10.026434579478906,\n",
       " (0, 'my'): -6.550269380382194,\n",
       " (0, 'age'): -9.264724727481665,\n",
       " (0, 'think'): -6.896002241624531,\n",
       " (0, 'far'): -7.746688978454683,\n",
       " (0, 'fetched'): -12.125420717231712,\n",
       " (0, 'What'): -7.5092585336295965,\n",
       " (0, 'pity'): -10.537260203244898,\n",
       " (0, 'it'): -4.503220360837481,\n",
       " (0, \"n't\"): -5.173850033717984,\n",
       " (0, '!'): -5.61720079372172,\n",
       " (0, 'Homelessness'): -15.069859696398153,\n",
       " (0, '('): -5.341320946326567,\n",
       " (0, 'or'): -5.885144872060943,\n",
       " (0, 'Houselessness'): -15.069859696398153,\n",
       " (0, 'George'): -9.164497848343583,\n",
       " (0, 'Carlin'): -13.683565335278262,\n",
       " (0, 'stated'): -10.850351991222047,\n",
       " (0, ')'): -5.310704514751945,\n",
       " (0, 'has'): -6.123354670399471,\n",
       " (0, 'been'): -6.541133269168243,\n",
       " (0, 'an'): -5.868660982339254,\n",
       " (0, 'issue'): -10.217829432478537,\n",
       " (0, 'for'): -5.135406564605145,\n",
       " (0, 'but'): -5.271066214976691,\n",
       " (0, 'never'): -7.0466350116814835,\n",
       " (0, 'plan'): -10.007264663371187,\n",
       " (0, 'help'): -8.295635810040539,\n",
       " (0, 'those'): -7.436006136716385,\n",
       " (0, 'on'): -5.366959509462872,\n",
       " (0, 'street'): -9.893709963824325,\n",
       " (0, 'were'): -6.326966224886016,\n",
       " (0, 'once'): -8.343626294039407,\n",
       " (0, 'considered'): -9.667182314525874,\n",
       " (0, 'human'): -8.793216207056508,\n",
       " (0, 'did'): -6.406490394824314,\n",
       " (0, 'everything'): -8.200845245732447,\n",
       " (0, 'from'): -5.932520217306461,\n",
       " (0, 'going'): -7.355182222597226,\n",
       " (0, 'work'): -7.52446994678633,\n",
       " (0, 'vote'): -10.505511504930316,\n",
       " (0, 'matter'): -8.829583851227383,\n",
       " (0, 'Most'): -9.186537307909875,\n",
       " (0, 'people'): -6.658027020639742,\n",
       " (0, 'homeless'): -11.026808428563603,\n",
       " (0, 'just'): -5.866040541412236,\n",
       " (0, 'lost'): -8.64986476825101,\n",
       " (0, 'cause'): -9.631780387474958,\n",
       " (0, 'while'): -7.5660189496992025,\n",
       " (0, 'worrying'): -12.074127422844162,\n",
       " (0, 'things'): -7.618618011410478,\n",
       " (0, 'racism'): -10.910976613038482,\n",
       " (0, 'war'): -8.958392356895475,\n",
       " (0, 'Iraq'): -11.263197206627833,\n",
       " (0, 'pressuring'): -13.971247407730043,\n",
       " (0, 'kids'): -8.254219706323822,\n",
       " (0, 'succeed'): -10.63904289755484,\n",
       " (0, 'technology'): -10.397030861936248,\n",
       " (0, 'elections'): -13.12394954734284,\n",
       " (0, 'inflation'): -13.683565335278262,\n",
       " (0, 'if'): -6.29864463402277,\n",
       " (0, 'they'): -5.744406517321466,\n",
       " (0, \"'ll\"): -7.731621546332564,\n",
       " (0, 'be'): -5.503384526335747,\n",
       " (0, 'next'): -8.457818661565062,\n",
       " (0, 'end'): -7.150139935473579,\n",
       " (0, 'up'): -6.313807097227703,\n",
       " (0, 'streets.'): -14.376712515838207,\n",
       " (0, '<'): -4.1969577936655975,\n",
       " (0, 'br'): -4.198685122904455,\n",
       " (0, '/'): -4.19616156999844,\n",
       " (0, '>'): -4.196275277429343,\n",
       " (0, 'But'): -6.874526029235283,\n",
       " (0, 'what'): -6.305493975868345,\n",
       " (0, 'you'): -5.405962708846552,\n",
       " (0, 'given'): -8.257514602220674,\n",
       " (0, 'bet'): -10.265838651664897,\n",
       " (0, 'live'): -8.831535071358646,\n",
       " (0, 'streets'): -10.63904289755484,\n",
       " (0, 'month'): -10.958985832224842,\n",
       " (0, 'without'): -7.7593095378637305,\n",
       " (0, 'luxuries'): -14.376712515838207,\n",
       " (0, 'had'): -6.34062434673888,\n",
       " (0, 'home'): -8.479558648201467,\n",
       " (0, 'entertainment'): -9.194928965546122,\n",
       " (0, 'sets'): -9.124439087791577,\n",
       " (0, 'bathroom'): -11.080875649833878,\n",
       " (0, 'pictures'): -10.128217273788849,\n",
       " (0, 'wall'): -10.172019896447242,\n",
       " (0, 'computer'): -9.453088598731583,\n",
       " (0, 'treasure'): -11.099567782846032,\n",
       " (0, 'like'): -5.800967437472355,\n",
       " (0, '?'): -5.733327299184211,\n",
       " (0, 'That'): -7.744710738442578,\n",
       " (0, 'Goddard'): -13.460421783964053,\n",
       " (0, 'Bolt'): -13.971247407730043,\n",
       " (0, 'lesson.'): -13.971247407730043,\n",
       " (0, 'Mel'): -11.178039398287526,\n",
       " (0, 'Brooks'): -11.080875649833878,\n",
       " (0, 'directs'): -11.51451163490874,\n",
       " (0, 'stars'): -8.513081340240111,\n",
       " (0, 'plays'): -8.346027255576944,\n",
       " (0, 'rich'): -9.732321616696835,\n",
       " (0, 'man'): -7.508217950809374,\n",
       " (0, 'world'): -8.003392726261195,\n",
       " (0, 'until'): -8.402902903968947,\n",
       " (0, 'deciding'): -12.02533725867473,\n",
       " (0, 'make'): -6.660251715661853,\n",
       " (0, 'with'): -5.151532793665385,\n",
       " (0, 'sissy'): -15.069859696398153,\n",
       " (0, 'rival'): -11.432273536671767,\n",
       " (0, 'Jeffery'): -12.990418154718316,\n",
       " (0, 'Tambor'): -13.460421783964053,\n",
       " (0, 'he'): -5.721149655157198,\n",
       " (0, 'thirty'): -10.821364454348794,\n",
       " (0, 'days'): -8.8592596193735,\n",
       " (0, ';'): -7.037499548473653,\n",
       " (0, 'succeeds'): -11.044508005663005,\n",
       " (0, 'do'): -5.958456072281994,\n",
       " (0, 'wants'): -8.653127413885827,\n",
       " (0, 'future'): -9.471437737399778,\n",
       " (0, 'project'): -9.513031634698615,\n",
       " (0, 'making'): -7.786411467641522,\n",
       " (0, 'more'): -6.286463464207259,\n",
       " (0, 'buildings'): -11.138034063673828,\n",
       " (0, 'where'): -7.091205967315422,\n",
       " (0, 'thrown'): -9.560471359770176,\n",
       " (0, 'bracelet'): -14.376712515838207,\n",
       " (0, 'his'): -5.714640063103886,\n",
       " (0, 'leg'): -11.009416685851734,\n",
       " (0, 'monitor'): -12.236646352341937,\n",
       " (0, 'every'): -7.604776959998605,\n",
       " (0, 'move'): -9.186537307909875,\n",
       " (0, 'ca'): -7.455547549946153,\n",
       " (0, 'step'): -10.233577789446676,\n",
       " (0, 'off'): -6.999266156448635,\n",
       " (0, 'sidewalk'): -12.872635119061934,\n",
       " (0, 'He'): -7.338806552391025,\n",
       " (0, 'nickname'): -13.278100227170098,\n",
       " (0, 'Pepto'): -15.069859696398153,\n",
       " (0, 'by'): -5.849965111617159,\n",
       " (0, 'vagrant'): -15.069859696398153,\n",
       " (0, 'after'): -7.059500107478369,\n",
       " (0, 'written'): -8.463209510199938,\n",
       " (0, 'forehead'): -12.125420717231712,\n",
       " (0, 'meets'): -9.694581288713989,\n",
       " (0, 'characters'): -6.916797749597103,\n",
       " (0, 'including'): -9.031988776476016,\n",
       " (0, 'woman'): -7.932581259137767,\n",
       " (0, 'name'): -8.342427971547298,\n",
       " (0, 'Molly'): -11.157836690970008,\n",
       " (0, 'Lesley'): -12.872635119061934,\n",
       " (0, 'Ann'): -10.865167077007188,\n",
       " (0, 'Warren'): -11.138034063673828,\n",
       " (0, 'ex-dancer'): -14.376712515838207,\n",
       " (0, 'got'): -7.478502649699602,\n",
       " (0, 'divorce'): -11.573352134931673,\n",
       " (0, 'before'): -7.477493567878357,\n",
       " (0, 'losing'): -10.700411843931132,\n",
       " (0, 'her'): -6.140291988572817,\n",
       " (0, 'pals'): -12.361809495295944,\n",
       " (0, 'Sailor'): -13.460421783964053,\n",
       " (0, 'Howard'): -10.548071119349112,\n",
       " (0, 'Morris'): -11.73765518622295,\n",
       " (0, 'Fumes'): -15.069859696398153,\n",
       " (0, 'Teddy'): -12.872635119061934,\n",
       " (0, 'Wilson'): -10.548071119349112,\n",
       " (0, 'are'): -5.457192468814309,\n",
       " (0, 'already'): -8.46591587179768,\n",
       " (0, 'used'): -8.226109747391929,\n",
       " (0, 'They'): -7.614561210714863,\n",
       " (0, \"'re\"): -7.368659515540707,\n",
       " (0, 'survivors'): -11.458941783753929,\n",
       " (0, 'not'): -5.440545866289014,\n",
       " (0, 'reaching'): -11.241218299909058,\n",
       " (0, 'mutual'): -12.361809495295944,\n",
       " (0, 'agreements'): -14.376712515838207,\n",
       " (0, 'when'): -6.437375460647181,\n",
       " (0, 'being'): -6.9776202896739425,\n",
       " (0, 'fight'): -8.81603088482268,\n",
       " (0, 'flight'): -10.975515134176053,\n",
       " (0, 'kill'): -8.56706965048253,\n",
       " (0, 'killed.'): -12.990418154718316,\n",
       " (0, 'While'): -8.694834876570058,\n",
       " (0, 'love'): -7.535631370124063,\n",
       " (0, 'connection'): -10.282367953616108,\n",
       " (0, 'between'): -7.875422845297819,\n",
       " (0, 'was'): -4.850029730917033,\n",
       " (0, 'necessary'): -10.35136082510306,\n",
       " (0, 'plot'): -6.807300723387496,\n",
       " (0, 'found'): -7.931786662353806,\n",
       " (0, 'Life'): -10.484892217727582,\n",
       " (0, 'Stinks'): -13.683565335278262,\n",
       " (0, 'observant'): -14.376712515838207,\n",
       " (0, 'films'): -7.080299247064287,\n",
       " (0, 'prior'): -10.675410541725714,\n",
       " (0, 'shows'): -8.336457804560794,\n",
       " (0, 'tender'): -12.297270974158371,\n",
       " (0, 'side'): -8.86732417921023,\n",
       " (0, 'compared'): -9.589220773056162,\n",
       " (0, 'slapstick'): -10.675410541725714,\n",
       " (0, 'Blazing'): -12.297270974158371,\n",
       " (0, 'Saddles'): -12.361809495295944,\n",
       " (0, 'Young'): -10.079427109619417,\n",
       " (0, 'Frankenstein'): -11.198658685490262,\n",
       " (0, 'Spaceballs'): -13.460421783964053,\n",
       " (0, 'show'): -7.183026697443096,\n",
       " (0, 'having'): -8.054147275910923,\n",
       " (0, 'something'): -7.149050017109553,\n",
       " (0, 'valuable'): -11.118615977816726,\n",
       " (0, 'day'): -8.249843331724023,\n",
       " (0, 'hand'): -8.765410893976172,\n",
       " (0, 'stupid'): -7.896667953911555,\n",
       " (0, 'know'): -6.991791814582715,\n",
       " (0, 'money'): -7.725786845825087,\n",
       " (0, 'Maybe'): -8.81027823233323,\n",
       " (0, 'should'): -7.055193325933211,\n",
       " (0, 'give'): -7.620361691015304,\n",
       " (0, 'instead'): -8.078682809276943,\n",
       " (0, 'using'): -9.063506536796421,\n",
       " (0, 'Monopoly'): -13.971247407730043,\n",
       " (0, 'money.'): -11.70256386641168,\n",
       " (0, 'Or'): -9.129688443677722,\n",
       " (0, 'maybe'): -8.311765191970423,\n",
       " (0, 'this'): -4.656276786675778,\n",
       " (0, 'film'): -5.255749955013242,\n",
       " (0, 'will'): -6.831058530526604,\n",
       " (0, 'inspire'): -11.73765518622295,\n",
       " (0, 'others'): -8.643371238940462,\n",
       " (0, 'Brilliant'): -12.361809495295944,\n",
       " (0, 'over-acting'): -12.125420717231712,\n",
       " (0, 'Best'): -10.164584917959724,\n",
       " (0, 'dramatic'): -9.50533928907546,\n",
       " (0, 'hobo'): -13.460421783964053,\n",
       " (0, 'lady'): -9.478872715887297,\n",
       " (0, 'have'): -5.431836207747374,\n",
       " (0, 'ever'): -7.053541797894739,\n",
       " (0, 'seen'): -7.002397029388096,\n",
       " (0, 'scenes'): -7.170706213055055,\n",
       " (0, 'clothes'): -9.899375701360002,\n",
       " (0, 'warehouse'): -11.486340757942044,\n",
       " (0, 'second'): -8.39026051055377,\n",
       " (0, 'none'): -8.87545430529348,\n",
       " (0, 'corn'): -11.774022830393823,\n",
       " (0, 'face'): -8.483688041543479,\n",
       " (0, 'good'): -6.224226440057967,\n",
       " (0, 'anything'): -7.579330294337441,\n",
       " (0, 'take'): -7.645694415356125,\n",
       " (0, 'lawyers'): -12.236646352341937,\n",
       " (0, 'also'): -7.0877848213169505,\n",
       " (0, 'superb'): -10.474739846263564,\n",
       " (0, 'After'): -8.410565776714515,\n",
       " (0, 'accused'): -11.241218299909058,\n",
       " (0, 'turncoat'): -15.069859696398153,\n",
       " (0, 'selling'): -11.099567782846032,\n",
       " (0, 'out'): -6.018749549992528,\n",
       " (0, 'boss'): -10.225672609939561,\n",
       " (0, 'dishonest'): -12.671964423599782,\n",
       " (0, 'lawyer'): -10.700411843931132,\n",
       " (0, 'shrugs'): -13.683565335278262,\n",
       " (0, 'indifferently'): -13.971247407730043,\n",
       " (0, 'says'): -8.713752035702262,\n",
       " (0, 'Three'): -10.559000189881303,\n",
       " (0, 'funny'): -7.386456015344327,\n",
       " (0, 'words'): -9.03917443613689,\n",
       " (0, 'Jeffrey'): -11.198658685490262,\n",
       " (0, 'favorite'): -9.509178065382626,\n",
       " (0, 'later'): -8.416996667044806,\n",
       " (0, 'Larry'): -10.63904289755484,\n",
       " (0, 'Sanders'): -11.811763158376671,\n",
       " (0, 'fantastic'): -10.225672609939561,\n",
       " (0, 'too'): -6.8181957727925635,\n",
       " (0, 'mad'): -9.934061259347892,\n",
       " (0, 'millionaire'): -12.125420717231712,\n",
       " (0, 'crush'): -11.356287629693846,\n",
       " (0, 'ghetto'): -11.811763158376671,\n",
       " (0, 'His'): -8.796982689851985,\n",
       " (0, 'character'): -6.938623146702037,\n",
       " (0, 'malevolent'): -12.767274603404108,\n",
       " (0, 'usual'): -9.056144540355351,\n",
       " (0, 'hospital'): -9.882473890557398,\n",
       " (0, 'scene'): -7.165524854313058,\n",
       " (0, 'invade'): -13.683565335278262,\n",
       " (0, 'demolition'): -12.767274603404108,\n",
       " (0, 'site'): -10.210047292036482,\n",
       " (0, 'all-time'): -11.458941783753929,\n",
       " (0, 'classics'): -10.675410541725714,\n",
       " (0, 'Look'): -10.307685761600396,\n",
       " (0, 'legs'): -10.627208439907836,\n",
       " (0, 'two'): -7.129631931252451,\n",
       " (0, 'big'): -7.837849364733395,\n",
       " (0, 'diggers'): -13.971247407730043,\n",
       " (0, 'fighting'): -9.410377480638532,\n",
       " (0, 'bleeds'): -14.376712515838207,\n",
       " (0, 'This'): -6.188857072142584,\n",
       " (0, 'movie'): -4.996249694525068,\n",
       " (0, 'gets'): -7.635011821186153,\n",
       " (0, 'better'): -6.997392327043383,\n",
       " (0, 'each'): -8.284272051390223,\n",
       " (0, 'quite'): -7.741422343502991,\n",
       " (0, 'often'): -8.658041428688255,\n",
       " (0, 'easily'): -9.085923415710962,\n",
       " (0, 'most'): -6.899108272640619,\n",
       " (0, 'underrated'): -11.51451163490874,\n",
       " (0, 'inn'): -12.584953046610153,\n",
       " (0, 'cannon'): -12.125420717231712,\n",
       " (0, 'Sure'): -9.703883681376302,\n",
       " (0, 'its'): -6.988384656261101,\n",
       " (0, 'flawed'): -10.992322252492434,\n",
       " (0, 'does'): -6.49969462021581,\n",
       " (0, 'realistic'): -9.667182314525874,\n",
       " (0, 'view'): -9.223420921340429,\n",
       " (0, 'homelessness'): -13.460421783964053,\n",
       " (0, 'unlike'): -10.202325245942571,\n",
       " (0, 'say'): -7.083694836065426,\n",
       " (0, 'how'): -6.821853994797532,\n",
       " (0, 'Citizen'): -11.332190078114785,\n",
       " (0, 'Kane'): -10.975515134176053,\n",
       " (0, 'gave'): -8.6353131776107,\n",
       " (0, 'lounge'): -12.990418154718316,\n",
       " (0, 'singers'): -11.573352134931673,\n",
       " (0, 'Titanic'): -11.044508005663005,\n",
       " (0, 'Italians'): -12.297270974158371,\n",
       " (0, 'YOU'): -10.369379330605737,\n",
       " (0, 'IDIOTS'): -15.069859696398153,\n",
       " (0, 'Many'): -10.039421775005717,\n",
       " (0, 'jokes'): -8.720720705018355,\n",
       " (0, 'fall'): -9.169962342815662,\n",
       " (0, 'flat'): -9.114022326933322,\n",
       " (0, 'still'): -7.447685101580531,\n",
       " (0, 'very'): -6.465571798130982,\n",
       " (0, 'lovable'): -11.356287629693846,\n",
       " (0, 'way'): -6.854041904565699,\n",
       " (0, 'comedies'): -9.982263361165769,\n",
       " (0, 'pull'): -9.934061259347892,\n",
       " (0, 'story'): -6.579832173054685,\n",
       " (0, 'traditionally'): -12.767274603404108,\n",
       " (0, 'reviled'): -13.971247407730043,\n",
       " (0, 'members'): -9.589220773056162,\n",
       " (0, 'society'): -9.761591998996948,\n",
       " (0, 'truly'): -8.544830038554691,\n",
       " (0, 'impressive'): -9.963914222497573,\n",
       " (0, 'Its'): -9.223420921340429,\n",
       " (0, 'Fisher'): -11.891805866050207,\n",
       " (0, 'King'): -9.232129249232214,\n",
       " (0, 'crap'): -8.405450676047746,\n",
       " (0, 'either'): -8.096316676878013,\n",
       " (0, 'only'): -6.303777237249291,\n",
       " (0, 'complaint'): -11.219712094688095,\n",
       " (0, 'cast'): -7.682150457317112,\n",
       " (0, 'someone'): -7.867943378866526,\n",
       " (0, 'else'): -8.016273969204477,\n",
       " (0, 'Director'): -9.667182314525874,\n",
       " (0, 'Writer'): -11.850983871529952,\n",
       " (0, 'so'): -5.9118658047941794,\n",
       " (0, 'typical'): -9.282962315031446,\n",
       " (0, 'less'): -8.197731595059167,\n",
       " (0, 'movies'): -6.820807422226861,\n",
       " (0, 'actually'): -7.324856892882314,\n",
       " (0, 'followable'): -13.971247407730043,\n",
       " (0, 'Leslie'): -11.080875649833878,\n",
       " (0, 'made'): -6.69861756046622,\n",
       " (0, 'she'): -6.4966643148666305,\n",
       " (0, 'under-rated'): -13.278100227170098,\n",
       " (0, 'actress'): -8.763584409450138,\n",
       " (0, 'There'): -6.902507709342083,\n",
       " (0, 'moments'): -8.506004169866026,\n",
       " (0, 'could'): -6.440767412484507,\n",
       " (0, 'fleshed'): -11.934365480469003,\n",
       " (0, 'bit'): -7.925452516077014,\n",
       " (0, 'probably'): -7.8472936775759825,\n",
       " (0, 'cut'): -8.829583851227383,\n",
       " (0, 'room'): -9.048836347048626,\n",
       " (0, 'worth'): -8.14918819214947,\n",
       " (0, 'price'): -10.700411843931132,\n",
       " (0, 'rent'): -9.065972629291615,\n",
       " (0, 'acting'): -6.815330814458409,\n",
       " (0, 'overall'): -9.282962315031446,\n",
       " (0, 'himself'): -8.257514602220674,\n",
       " (0, 'job'): -8.44579446859826,\n",
       " (0, 'characteristic'): -12.02533725867473,\n",
       " (0, 'speaking'): -10.007264663371187,\n",
       " (0, 'directly'): -10.49514871789477,\n",
       " (0, 'audience'): -8.048775732109013,\n",
       " (0, 'Again'): -10.387728469273933,\n",
       " (0, 'best'): -7.518147481046842,\n",
       " (0, 'actor'): -8.060450763689516,\n",
       " (0, 'Fume'): -15.069859696398153,\n",
       " (0, 'both'): -8.110461184264178,\n",
       " (0, 'played'): -8.160106414753344,\n",
       " (0, 'parts'): -8.789463857437958,\n",
       " (0, 'well'): -7.091548726530432,\n",
       " (0, 'comedic'): -10.290736203286624,\n",
       " (0, 'Robin'): -10.274069150801411,\n",
       " (0, 'Williams'): -10.079427109619417,\n",
       " (0, 'nor'): -9.172705828761412,\n",
       " (0, 'quirky/insane'): -15.069859696398153,\n",
       " (0, 'recent'): -9.718001562922087,\n",
       " (0, 'thriller'): -9.33328739891896,\n",
       " (0, 'fame'): -10.615512400144645,\n",
       " (0, 'hybrid'): -11.668662314735998,\n",
       " (0, 'drama'): -8.908652374703077,\n",
       " (0, 'over-dramatization'): -15.069859696398153,\n",
       " (0, 'mixed'): -10.435130708168517,\n",
       " (0, 'new'): -7.8761738780030415,\n",
       " (0, 'per'): -10.910976613038482,\n",
       " (0, 'se'): -12.297270974158371,\n",
       " (0, 'mystery/suspense'): -15.069859696398153,\n",
       " (0, 'vehicle'): -10.274069150801411,\n",
       " (0, 'attempts'): -9.214787774195726,\n",
       " (0, 'locate'): -12.236646352341937,\n",
       " (0, 'sick'): -9.482611037997904,\n",
       " (0, 'boy'): -8.767240720653248,\n",
       " (0, 'keeper.'): -15.069859696398153,\n",
       " (0, 'Also'): -8.586752344940955,\n",
       " (0, 'starring'): -9.876902845507942,\n",
       " (0, 'Sandra'): -11.850983871529952,\n",
       " (0, 'Oh'): -8.515926292372342,\n",
       " (0, 'Rory'): -13.683565335278262,\n",
       " (0, 'Culkin'): -11.978817243039837,\n",
       " (0, 'Suspense'): -12.767274603404108,\n",
       " (0, 'Drama'): -12.361809495295944,\n",
       " (0, 'pretty'): -7.458511978994532,\n",
       " (0, 'news'): -10.032907093984525,\n",
       " (0, 'report'): -11.543499171781992,\n",
       " (0, 'William'): -9.741983527608571,\n",
       " (0, 'close'): -8.851259576706424,\n",
       " (0, 'achieving'): -12.584953046610153,\n",
       " (0, 'goal.'): -15.069859696398153,\n",
       " (0, 'must'): -7.78709851679256,\n",
       " (0, 'highly'): -9.513031634698615,\n",
       " (0, 'entertained'): -10.257675341025736,\n",
       " (0, 'though'): -7.5186728291020035,\n",
       " (0, 'fails'): -8.923530438729255,\n",
       " (0, 'teach'): -10.713150869708562,\n",
       " (0, 'guide'): -11.543499171781992,\n",
       " (0, 'inspect'): -13.971247407730043,\n",
       " (0, 'amuse'): -12.179487938501989,\n",
       " (0, 'felt'): -8.358119301341974,\n",
       " (0, 'watching'): -7.258291207052974,\n",
       " (0, 'guy'): -7.557242151723642,\n",
       " (0, 'performing'): -11.263197206627833,\n",
       " (0, 'actions'): -10.257675341025736,\n",
       " (0, 'third'): -9.399978773417633,\n",
       " (0, 'person'): -8.380260427219186,\n",
       " (0, 'perspective'): -10.603951577743569,\n",
       " (0, 'In'): -7.136779924517739,\n",
       " (0, 'real'): -7.483056161235573,\n",
       " (0, 'able'): -8.80836801207711,\n",
       " (0, 'subscribe'): -13.460421783964053,\n",
       " (0, 'premise'): -8.91076430790622,\n",
       " (0, 'story.'): -10.675410541725714,\n",
       " (0, 'All'): -8.22717641415973,\n",
       " (0, 'watch'): -6.988384656261101,\n",
       " (0, 'definitely'): -8.938633206915013,\n",
       " (0, 'Friday/Saturday'): -15.069859696398153,\n",
       " (0, 'night'): -8.452456718423676,\n",
       " (0, 'fare.'): -13.683565335278262,\n",
       " (0, 'rates'): -11.51451163490874,\n",
       " (0, '7.7/10'): -15.069859696398153,\n",
       " (0, '...'): -6.408912541337219,\n",
       " (0, 'Fiend'): -12.430802366782894,\n",
       " (0, 'Yes'): -9.006074487710546,\n",
       " (0, 'art'): -8.985360283322981,\n",
       " (0, 'successfully'): -10.779400255249762,\n",
       " (0, 'slow'): -8.765410893976172,\n",
       " (0, 'paced'): -10.992322252492434,\n",
       " (0, 'thriller.'): -13.278100227170098,\n",
       " (0, 'unfolds'): -11.978817243039837,\n",
       " (0, 'nice'): -8.367899330395613,\n",
       " (0, 'volumes'): -12.767274603404108,\n",
       " (0, 'even'): -6.260146155889886,\n",
       " (0, 'notice'): -9.893709963824325,\n",
       " (0, 'happening.'): -12.671964423599782,\n",
       " (0, 'Fine'): -12.236646352341937,\n",
       " (0, 'performance'): -8.215505194143132,\n",
       " (0, 'sexuality'): -11.157836690970008,\n",
       " (0, 'angles'): -10.603951577743569,\n",
       " (0, 'seem'): -8.02757352445841,\n",
       " (0, 'unnecessary'): -9.741983527608571,\n",
       " (0, 'affect'): -11.934365480469003,\n",
       " (0, 'enjoy'): -8.599060192615552,\n",
       " (0, 'However'): -8.196695862185635,\n",
       " (0, 'core'): -10.651019088601554,\n",
       " (0, 'engaging'): -10.299175071932488,\n",
       " (0, 'rush'): -11.219712094688095,\n",
       " (0, 'onto'): -9.93996098147508,\n",
       " (0, 'grips'): -12.767274603404108,\n",
       " (0, 'enough'): -7.494275044840361,\n",
       " (0, 'keep'): -8.475446236648375,\n",
       " (0, 'wondering'): -9.667182314525874,\n",
       " (0, 'direction'): -8.546297390248641,\n",
       " (0, 'Use'): -12.430802366782894,\n",
       " (0, 'lights'): -10.895472426502517,\n",
       " (0, 'achieve'): -10.687833061724271,\n",
       " (0, 'desired'): -11.380980242284217,\n",
       " (0, 'affects'): -12.02533725867473,\n",
       " (0, 'suspense'): -9.264724727481665,\n",
       " (0, 'unexpectedness'): -14.376712515838207,\n",
       " (0, 'good.'): -11.080875649833878,\n",
       " (0, 'Very'): -9.854923938789167,\n",
       " (0, '1'): -8.244399660142847,\n",
       " (0, 'looking'): -7.950224058380517,\n",
       " (0, 'lay'): -11.241218299909058,\n",
       " (0, 'back'): -7.358310716769007,\n",
       " (0, 'hear'): -9.178215484572382,\n",
       " (0, 'thrilling'): -11.026808428563603,\n",
       " (0, 'short'): -8.408004955852842,\n",
       " (0, 'critically'): -12.671964423599782,\n",
       " (0, 'acclaimed'): -11.811763158376671,\n",
       " (0, 'psychological'): -10.537260203244898,\n",
       " (0, 'based'): -8.712017429890054,\n",
       " (0, 'true'): -8.46591587179768,\n",
       " (0, 'events'): -9.226315279366794,\n",
       " (0, 'Gabriel'): -11.044508005663005,\n",
       " (0, 'celebrated'): -11.891805866050207,\n",
       " (0, 'writer'): -8.980814820951307,\n",
       " (0, 'late-night'): -12.361809495295944,\n",
       " (0, 'talk'): -9.027226862715771,\n",
       " (0, 'host'): -11.026808428563603,\n",
       " (0, 'becomes'): -8.59288733350847,\n",
       " (0, 'captivated'): -12.990418154718316,\n",
       " (0, 'harrowing'): -12.430802366782894,\n",
       " (0, 'young'): -8.01713864716583,\n",
       " (0, 'listener'): -12.990418154718316,\n",
       " (0, 'adoptive'): -14.376712515838207,\n",
       " (0, 'mother'): -8.75812488724524,\n",
       " (0, 'Toni'): -11.978817243039837,\n",
       " (0, 'Collette'): -12.361809495295944,\n",
       " (0, 'troubling'): -12.990418154718316,\n",
       " (0, 'questions'): -9.694581288713989,\n",
       " (0, 'arise'): -12.872635119061934,\n",
       " (0, 'however'): -8.453794511265336,\n",
       " (0, 'finds'): -9.194928965546122,\n",
       " (0, 'drawn'): -10.000955494177921,\n",
       " (0, 'into'): -6.650720445457304,\n",
       " (0, 'widening'): -13.683565335278262,\n",
       " (0, 'mystery'): -9.445842190210815,\n",
       " (0, 'hides'): -11.573352134931673,\n",
       " (0, 'deadly'): -10.700411843931132,\n",
       " (0, 'secret'): -9.680787966581653,\n",
       " (0, 'according'): -10.454739179556894,\n",
       " (0, 'official'): -11.406298050268507,\n",
       " (0, 'synopsis.'): -12.872635119061934,\n",
       " (0, 'You'): -7.674138087796108,\n",
       " (0, 'really'): -6.372848078406079,\n",
       " (0, 'STOP'): -12.584953046610153,\n",
       " (0, 'reading'): -9.223420921340429,\n",
       " (0, 'these'): -7.29458384991129,\n",
       " (0, 'comments'): -9.129688443677722,\n",
       " (0, 'NOW'): -12.074127422844162,\n",
       " (0, 'How'): -8.375297637877058,\n",
       " (0, 'lose'): -10.217829432478537,\n",
       " (0, 'ending'): -8.051457897328952,\n",
       " (0, 'Ms.'): -10.164584917959724,\n",
       " (0, 'planning'): -10.942725311353062,\n",
       " (0, 'chopped'): -11.263197206627833,\n",
       " (0, 'sent'): -10.107015066138246,\n",
       " (0, 'deleted'): -11.380980242284217,\n",
       " (0, 'land'): -10.179510568176399,\n",
       " (0, 'overkill'): -12.990418154718316,\n",
       " (0, 'nature'): -9.623122324731844,\n",
       " (0, 'physical'): -10.299175071932488,\n",
       " (0, 'mental'): -10.013613891049845,\n",
       " (0, 'ailments'): -13.971247407730043,\n",
       " (0, 'obvious'): -8.61466113305803,\n",
       " (0, 'Mr.'): -9.132323491315727,\n",
       " (0, 'returns'): -10.316269505291789,\n",
       " (0, 'New'): -8.947366886883767,\n",
       " (0, 'York'): -9.424412798754915,\n",
       " (0, 'Possibly'): -11.668662314735998,\n",
       " (0, 'blindness'): -15.069859696398153,\n",
       " (0, 'question'): -9.223420921340429,\n",
       " (0, '-'): -6.569609225712227,\n",
       " (0, 'revelation'): -11.138034063673828,\n",
       " (0, 'certain'): -9.336518419500408,\n",
       " (0, 'highway'): -12.02533725867473,\n",
       " (0, 'video'): -8.31060442573446,\n",
       " (0, 'tape'): -10.548071119349112,\n",
       " (0, 'would'): -6.13751512728433,\n",
       " (0, 'benefit'): -10.992322252492434,\n",
       " (0, 're-editing'): -13.683565335278262,\n",
       " (0, 'director'): -7.47799798150822,\n",
       " (0, 'Bobby'): -10.975515134176053,\n",
       " (0, 'Cannavale'): -15.069859696398153,\n",
       " (0, 'Jess'): -11.70256386641168,\n",
       " (0, 'initially'): -11.009416685851734,\n",
       " (0, 'believable'): -9.606027891372543,\n",
       " (0, 'couple'): -8.286534495794193,\n",
       " (0, 'establishing'): -11.668662314735998,\n",
       " (0, 'relationship'): -9.346274594445772,\n",
       " (0, 'might'): -7.675981406290397,\n",
       " (0, 'helped'): -10.194662373197001,\n",
       " (0, 'set'): -8.113314253246584,\n",
       " (0, 'stage'): -9.435070093228903,\n",
       " (0, 'Otherwise'): -10.274069150801411,\n",
       " (0, 'exemplary'): -13.683565335278262,\n",
       " (0, 'offers'): -10.265838651664897,\n",
       " (0, 'exceptionally'): -11.380980242284217,\n",
       " (0, 'strong'): -9.372766209892749,\n",
       " (0, 'characterization'): -10.895472426502517,\n",
       " (0, 'gay'): -9.237977219114637,\n",
       " (0, 'impersonation'): -12.125420717231712,\n",
       " (0, 'Anna'): -10.592522881919948,\n",
       " (0, 'Joe'): -9.417370516129504,\n",
       " (0, 'Morton'): -12.504910338936616,\n",
       " (0, 'Ashe'): -15.069859696398153,\n",
       " (0, 'Pete'): -11.543499171781992,\n",
       " (0, 'Logand'): -15.069859696398153,\n",
       " (0, 'perfect.'): -14.376712515838207,\n",
       " (0, 'Donna'): -11.263197206627833,\n",
       " (0, 'belongs'): -10.865167077007188,\n",
       " (0, 'creepy'): -9.386279929059471,\n",
       " (0, 'hall'): -11.811763158376671,\n",
       " (0, 'correct'): -10.37851181416901,\n",
       " (0, 'saying'): -8.66297971032884,\n",
       " (0, \"'Psycho\"): -13.971247407730043,\n",
       " (0, 'several'): -8.679619029332803,\n",
       " (0, 'organizations'): -12.990418154718316,\n",
       " (0, 'giving'): -9.03917443613689,\n",
       " (0, 'awards'): -10.835753191800894,\n",
       " (0, 'seemed'): -8.319928502609583,\n",
       " (0, 'reach'): -10.316269505291789,\n",
       " (0, 'women'): -8.287667640391362,\n",
       " (0, 'due'): -9.075898269091583,\n",
       " (0, 'slighter'): -15.069859696398153,\n",
       " (0, 'dispersion'): -15.069859696398153,\n",
       " (0, 'roles'): -9.063506536796421,\n",
       " (0, 'certainly'): -8.684665297400429,\n",
       " (0, 'noticed'): -10.265838651664897,\n",
       " (0, 'award'): -10.505511504930316,\n",
       " (0, 'consideration'): -11.73765518622295,\n",
       " (0, 'She'): -8.075926721174964,\n",
       " (0, 'And'): -6.872320956676969,\n",
       " (0, 'Patrick'): -10.779400255249762,\n",
       " (0, 'Stettner'): -15.069859696398153,\n",
       " (0, 'evokes'): -12.504910338936616,\n",
       " (0, 'Hitchcock'): -10.752371582861842,\n",
       " (0, 'makes'): -7.5838070785350125,\n",
       " (0, 'getting'): -8.279762460884248,\n",
       " (0, 'sandwich'): -12.584953046610153,\n",
       " (0, 'vending'): -14.376712515838207,\n",
       " (0, 'machine'): -10.179510568176399,\n",
       " (0, 'suspenseful.'): -15.069859696398153,\n",
       " (0, 'Finally'): -10.020003689148616,\n",
       " (0, 'writers'): -9.119217143810426,\n",
       " (0, 'Armistead'): -15.069859696398153,\n",
       " (0, 'Maupin'): -14.376712515838207,\n",
       " (0, 'Terry'): -11.332190078114785,\n",
       " (0, 'Anderson'): -10.397030861936248,\n",
       " (0, 'deserve'): -9.854923938789167,\n",
       " (0, 'gratitude'): -13.460421783964053,\n",
       " (0, 'attendants'): -13.683565335278262,\n",
       " (0, 'everywhere.'): -13.683565335278262,\n",
       " (0, '*'): -6.719902424357829,\n",
       " (0, 'Night'): -9.54440675726637,\n",
       " (0, 'Listener'): -13.460421783964053,\n",
       " (0, '1/21/06'): -15.069859696398153,\n",
       " (0, '~'): -11.241218299909058,\n",
       " (0, 'THE'): -8.501781784986177,\n",
       " (0, 'NIGHT'): -12.02533725867473,\n",
       " (0, 'LISTENER'): -15.069859696398153,\n",
       " (0, '2006'): -10.926724970006621,\n",
       " (0, '1/2'): -10.045979175551876,\n",
       " (0, 'John'): -8.342427971547298,\n",
       " (0, 'Cullum'): -15.069859696398153,\n",
       " (0, 'Lisa'): -10.592522881919948,\n",
       " (0, 'Emery'): -14.376712515838207,\n",
       " (0, 'Becky'): -13.278100227170098,\n",
       " (0, 'Baker'): -10.850351991222047,\n",
       " (0, 'Dir'): -13.12394954734284,\n",
       " (0, 'Hitchcockian'): -13.971247407730043,\n",
       " (0, 'suspenser'): -14.376712515838207,\n",
       " (0, 'gives'): -8.77091044954221,\n",
       " (0, 'stand-out'): -13.12394954734284,\n",
       " (0, 'low-key'): -12.236646352341937,\n",
       " (0, 'performance.'): -12.361809495295944,\n",
       " (0, 'celebrities'): -12.361809495295944,\n",
       " (0, 'fans'): -8.73126561819497,\n",
       " (0, 'near'): -9.140270553008259,\n",
       " (0, 'paranoia'): -11.978817243039837,\n",
       " (0, 'associates'): -12.504910338936616,\n",
       " (0, 'why'): -7.2929052930757114,\n",
       " (0, 'almost'): -7.763999663714144,\n",
       " (0, 'norm'): -11.978817243039837,\n",
       " (0, 'latest'): -10.454739179556894,\n",
       " (0, 'derange'): -14.376712515838207,\n",
       " (0, 'fan'): -8.295635810040539,\n",
       " (0, 'scenario'): -10.37851181416901,\n",
       " (0, 'no'): -6.2487174600662625,\n",
       " (0, 'talk-radio'): -15.069859696398153,\n",
       " (0, 'personality'): -10.172019896447242,\n",
       " (0, 'named'): -9.229218039024754,\n",
       " (0, 'No'): -8.152154086562849,\n",
       " (0, 'reads'): -11.157836690970008,\n",
       " (0, 'stories'): -8.94517630550395,\n",
       " (0, 'penned'): -12.179487938501989,\n",
       " (0, 'over'): -7.137138668916205,\n",
       " (0, 'airwaves'): -13.278100227170098,\n",
       " (0, 'accumulated'): -13.971247407730043,\n",
       " (0, 'interesting'): -7.704679570377141,\n",
       " (0, 'form'): -9.34954791979074,\n",
       " (0, 'submitted'): -12.297270974158371,\n",
       " (0, 'manuscript'): -13.278100227170098,\n",
       " (0, 'travails'): -13.971247407730043,\n",
       " (0, 'troubled'): -11.604123793598427,\n",
       " (0, 'youth'): -10.505511504930316,\n",
       " (0, 'editor'): -10.910976613038482,\n",
       " (0, 'read'): -8.1383878907987,\n",
       " (0, 'naturally'): -10.515982804797613,\n",
       " (0, 'disturbed'): -11.044508005663005,\n",
       " (0, 'ultimately'): -9.737140903132785,\n",
       " (0, 'intrigued'): -11.099567782846032,\n",
       " (0, 'nightmarish'): -12.430802366782894,\n",
       " (0, 'existence'): -10.307685761600396,\n",
       " (0, 'abducted'): -11.978817243039837,\n",
       " (0, 'sexually'): -10.793193577382098,\n",
       " (0, 'abused'): -11.432273536671767,\n",
       " (0, 'finally'): -8.754501694875819,\n",
       " (0, 'rescued'): -11.486340757942044,\n",
       " (0, 'nurse'): -11.062526511165682,\n",
       " (0, 'excellent'): -9.127060321271452,\n",
       " (0, 'adopted'): -11.486340757942044,\n",
       " (0, 'correspondence'): -13.971247407730043,\n",
       " (0, 'reveals'): -11.099567782846032,\n",
       " (0, 'dying'): -10.013613891049845,\n",
       " (0, 'AIDS'): -12.074127422844162,\n",
       " (0, 'Naturally'): -11.30865958070459,\n",
       " (0, 'meet'): -9.548398778535907,\n",
       " (0, 'suddenly'): -9.4138678855783,\n",
       " (0, 'doubt'): -9.142933670427743,\n",
       " (0, 'possibly'): -9.08089827950829,\n",
       " (0, 'devious'): -12.361809495295944,\n",
       " (0, 'ulterior'): -13.460421783964053,\n",
       " (0, 'motives'): -11.241218299909058,\n",
       " (0, 'seed'): -12.504910338936616,\n",
       " (0, 'planted'): -12.179487938501989,\n",
       " (0, 'estranged'): -11.978817243039837,\n",
       " (0, 'lover'): -10.065913390452694,\n",
       " (0, 'whose'): -9.063506536796421,\n",
       " (0, 'sudden'): -10.397030861936248,\n",
       " (0, 'departure'): -12.074127422844162,\n",
       " (0, 'City'): -10.202325245942571,\n",
       " (0, 'apartment'): -10.52656491412815,\n",
       " (0, 'emotional'): -9.727525444433342,\n",
       " (0, 'tailspin'): -15.069859696398153,\n",
       " (0, 'now'): -7.795380137624282,\n",
       " (0, 'grown'): -10.505511504930316,\n",
       " (0, 'tempest'): -14.376712515838207,\n",
       " (0, 'teacup'): -13.971247407730043,\n",
       " (0, 'decides'): -9.493910593251837,\n",
       " (0, 'investigating'): -11.543499171781992,\n",
       " (0, 'backgrounds'): -11.604123793598427,\n",
       " (0, 'discovering'): -11.850983871529952,\n",
       " (0, 'truths'): -12.504910338936616,\n",
       " (0, 'anticipate.'): -15.069859696398153,\n",
       " (0, 'Written'): -11.934365480469003,\n",
       " (0, 'co-wrote'): -12.179487938501989,\n",
       " (0, 'screenplay'): -9.286034514068415,\n",
       " (0, 'former'): -9.694581288713989,\n",
       " (0, 'novice'): -13.278100227170098,\n",
       " (0, 'hoax'): -13.278100227170098,\n",
       " (0, 'run'): -8.738357846504462,\n",
       " (0, 'full'): -8.586752344940955,\n",
       " (0, 'tilt'): -13.971247407730043,\n",
       " (0, 'any'): -6.668975627382299,\n",
       " (0, 'old'): -7.519724353909724,\n",
       " (0, 'fashioned'): -11.850983871529952,\n",
       " (0, 'pot-boiler'): -14.376712515838207,\n",
       " (0, 'helps'): -10.581223326666013,\n",
       " (0, 'conflicted'): -13.278100227170098,\n",
       " (0, 'good-hearted'): -13.460421783964053,\n",
       " (0, 'genuinely'): -10.505511504930316,\n",
       " (0, 'number'): -9.0537025366998,\n",
       " (0, 'fact'): -7.5682252385147395,\n",
       " (0, 'him'): -6.845428123176996,\n",
       " (0, 'thing'): -7.145063782441718,\n",
       " (0, 'escaped'): -11.178039398287526,\n",
       " (0, 'own'): -7.897435119273308,\n",
       " (0, 'unsettling'): -11.635872491913007,\n",
       " (0, 'dreadful'): -9.817586268351523,\n",
       " (0, 'trait'): -12.990418154718316,\n",
       " (0, 'leave'): -8.81988445413867,\n",
       " (0, 'unmentioned'): -14.376712515838207,\n",
       " (0, 'underlines'): -12.990418154718316,\n",
       " (0, 'desperation'): -11.432273536671767,\n",
       " (0, 'rattle'): -13.278100227170098,\n",
       " (0, 'core.'): -13.971247407730043,\n",
       " (0, 'runs'): -9.606027891372543,\n",
       " (0, 'gas'): -10.700411843931132,\n",
       " (0, 'eventually'): -9.442238582707516,\n",
       " (0, 'repetitive'): -10.592522881919948,\n",
       " (0, 'predictable'): -8.672930041182006,\n",
       " (0, 'despite'): -8.989926501302563,\n",
       " (0, 'finely'): -13.683565335278262,\n",
       " (0, 'directed'): -8.835448970679781,\n",
       " (0, 'piece'): -8.315255596910191,\n",
       " (0, 'hoodwink'): -14.376712515838207,\n",
       " (0, 'pays'): -11.458941783753929,\n",
       " (0, 'listen'): -10.079427109619417,\n",
       " (0, 'inner'): -10.942725311353062,\n",
       " (0, 'voice'): -8.967301101784583,\n",
       " (0, 'careful'): -11.486340757942044,\n",
       " (0, 'hope'): -8.651494760461942,\n",
       " (0, 'God'): -9.017770527473736,\n",
       " (0, 'bless'): -12.430802366782894,\n",
       " (0, 'constantly'): -9.817586268351523,\n",
       " (0, 'shooting'): -9.560471359770176,\n",
       " (0, 'foot'): -10.397030861936248,\n",
       " (0, 'lately'): -11.356287629693846,\n",
       " (0, 'dumb'): -9.001434108154044,\n",
       " (0, 'done'): -7.798851158117161,\n",
       " (0, 'decade'): -10.49514871789477,\n",
       " (0, 'perhaps'): -8.845301267122792,\n",
       " (0, 'exception'): -9.64490967891675,\n",
       " (0, 'Death'): -10.342471877685812,\n",
       " (0, 'To'): -8.347229901542706,\n",
       " (0, 'Smoochy'): -14.376712515838207,\n",
       " (0, 'bombed'): -12.074127422844162,\n",
       " (0, 'came'): -8.439176310755782,\n",
       " (0, 'cult'): -9.658213644543114,\n",
       " (0, 'dramas'): -11.573352134931673,\n",
       " (0, 'especially'): -8.304820719617611,\n",
       " (0, 'Insomnia'): -15.069859696398153,\n",
       " (0, 'One'): -8.166112438813554,\n",
       " (0, 'Hour'): -12.297270974158371,\n",
       " (0, 'Photo'): -14.376712515838207,\n",
       " (0, 'mediocre'): -9.471437737399778,\n",
       " (0, 'reviews'): -9.068444818437003,\n",
       " (0, 'quick'): -9.934061259347892,\n",
       " (0, 'DVD'): -8.215505194143132,\n",
       " (0, 'release'): -9.356126890888785,\n",
       " (0, 'among'): -9.475148316796314,\n",
       " (0, 'period.'): -12.767274603404108,\n",
       " (0, 'chilling'): -11.934365480469003,\n",
       " (0, 'include'): -9.945895716994894,\n",
       " (0, 'serial'): -9.969993268573955,\n",
       " (0, 'killer'): -8.476815162255717,\n",
       " (0, 'anyone'): -7.923875228683765,\n",
       " (0, 'physically'): -10.821364454348794,\n",
       " (0, 'dangerous'): -10.369379330605737,\n",
       " (0, 'concept'): -9.372766209892749,\n",
       " (0, 'actual'): -9.006074487710546,\n",
       " (0, 'case'): -8.441818320218621,\n",
       " (0, 'fraud'): -12.074127422844162,\n",
       " (0, 'yet'): -8.140342925634503,\n",
       " (0, 'officially'): -12.074127422844162,\n",
       " (0, 'confirmed'): -12.179487938501989,\n",
       " (0, 'high'): -8.34843399560751,\n",
       " (0, 'autobiography'): -12.361809495295944,\n",
       " (0, 'child'): -8.831535071358646,\n",
       " (0, 'Anthony'): -10.265838651664897,\n",
       " (0, 'Godby'): -15.069859696398153,\n",
       " (0, 'Johnson'): -10.726054274544468,\n",
       " (0, 'suffered'): -10.807179819356838,\n",
       " (0, 'horrific'): -10.63904289755484,\n",
       " (0, 'abuse'): -10.484892217727582,\n",
       " (0, 'contracted'): -13.460421783964053,\n",
       " (0, 'result'): -9.217657216623678,\n",
       " (0, 'moved'): -10.36032949508582,\n",
       " (0, 'reports'): -11.668662314735998,\n",
       " (0, 'online'): -11.356287629693846,\n",
       " (0, 'may'): -7.888267751786288,\n",
       " (0, 'exist'): -9.93996098147508,\n",
       " (0, 'confused'): -9.718001562922087,\n",
       " (0, 'feelings'): -10.397030861936248,\n",
       " (0, 'brilliantly'): -11.332190078114785,\n",
       " (0, 'portrayed'): -9.54440675726637,\n",
       " (0, 'resurfaced'): -13.971247407730043,\n",
       " (0, 'mind.'): -12.236646352341937,\n",
       " (0, 'sociopathic'): -13.683565335278262,\n",
       " (0, 'caretaker'): -11.934365480469003,\n",
       " (0, 'Her'): -9.427952625460039,\n",
       " (0, 'role'): -8.005955734926085,\n",
       " (0, 'cry'): -10.42546879725678,\n",
       " (0, 'Little'): -9.893709963824325,\n",
       " (0, 'Miss'): -10.35136082510306,\n",
       " (0, 'Sunshine'): -11.774022830393823,\n",
       " (0, 'times'): -7.879937525652346,\n",
       " (0, 'looked'): -8.568570025857763,\n",
       " (0, 'camera'): -8.232526881712563,\n",
       " (0, 'thought'): -7.610520801177858,\n",
       " (0, 'staring'): -11.009416685851734,\n",
       " (0, 'takes'): -8.235750957584315,\n",
       " (0, 'play'): -8.241147624756469,\n",
       " (0, 'sort'): -8.375297637877058,\n",
       " (0, 'understated'): -12.297270974158371,\n",
       " (0, 'reviewed'): -11.635872491913007,\n",
       " (0, 'actresses'): -10.121099806019984,\n",
       " (0, 'generation'): -10.713150869708562,\n",
       " (0, 'nominated'): -11.263197206627833,\n",
       " (0, 'Academy'): -10.713150869708562,\n",
       " (0, 'Award'): -11.432273536671767,\n",
       " (0, '2008'): -11.486340757942044,\n",
       " (0, 'incredible'): -10.342471877685812,\n",
       " (0, 'there'): -6.198494691261302,\n",
       " (0, 'least'): -7.476989408553335,\n",
       " (0, 'scary'): -8.847283428326785,\n",
       " (0, 'too.'): -11.062526511165682,\n",
       " (0, 'dark'): -9.065972629291615,\n",
       " (0, 'recommend'): -8.564075636269925,\n",
       " (0, 'Be'): -10.807179819356838,\n",
       " (0, 'prepared'): -10.700411843931132,\n",
       " (0, 'unsettled'): -13.460421783964053,\n",
       " (0, 'because'): -6.609660226502036,\n",
       " ...}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loglikehood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b4cbc0",
   "metadata": {},
   "source": [
    "## Test the model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359a8b6a",
   "metadata": {},
   "source": [
    "### Test on training IMDB dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbb2f518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the train accuracy is about: 0.5671796361190619\n"
     ]
    }
   ],
   "source": [
    "''' Get the best result of each word according to the loglikehood '''\n",
    "train_y_pred = np.array([0 if (loglikehood[(0, word)] > loglikehood[(1, word)]) else 1 for word in train_dataset['word']])\n",
    "\n",
    "''' Compare to ground truth '''\n",
    "train_y_gt = train_dataset['label'].to_numpy()\n",
    "\n",
    "not_preprocessing_train_accuracy = (train_y_pred == train_y_gt).sum() / len(train_dataset)\n",
    "print(f\"the train accuracy is about: {not_preprocessing_train_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e103c8a3",
   "metadata": {},
   "source": [
    "### Test on test IMDB dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad2dfe05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the test accuracy is about: 0.5461215708366166\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Get the best result of each word according to the loglikehood\n",
    "we choose the label 0 in case of unknown word (not in vocabulary)\n",
    "'''\n",
    "test_y_pred = np.array([0 if (word not in vocabulary or loglikehood[(0, word)] > loglikehood[(1, word)]) else 1 for word in test_dataset['word']])\n",
    "\n",
    "''' Compare to ground truth '''\n",
    "test_y_gt = test_dataset['label'].to_numpy()\n",
    "\n",
    "not_preprocessing_test_accuracy = (test_y_pred == test_y_gt).sum() / len(test_dataset)\n",
    "print(f\"the test accuracy is about: {not_preprocessing_test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bebf5d",
   "metadata": {},
   "source": [
    "## Add some pre-processing on IMDB dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe3583b",
   "metadata": {},
   "source": [
    "### Stop word filtering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a7fe555",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_stop_word = [\"the\", \"and\", \"a\", \"of\", \"to\", \"is\", \"it\", \"in\", \"this\", \"that\", \"s\", \"was\", \"as\", \"for\", \"with\", \"but\", \"then\", \"an\", \"at\", \"who\", \"when\", \"than\", \"where\", \"which\", \"with\", \"on\", \"t\", \"are\", \"by\", \"so\", \"from\", \"have\", \"be\", \"or\", \"just\", \"about\", \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab30ecf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of base train dataset is: 7065333\n",
      "Size of cleaned train dataset is: 5233280\n"
     ]
    }
   ],
   "source": [
    "cleaned_train_dataset = train_dataset[~train_dataset.word.isin(list_of_stop_word)]\n",
    "cleaned_test_dataset = test_dataset[~test_dataset.word.isin(list_of_stop_word)]\n",
    "\n",
    "\n",
    "cleaned_vocabulary = cleaned_train_dataset['word'].factorize()[1]\n",
    "print(f\"Size of base train dataset is: {len(train_dataset)}\")\n",
    "print(f\"Size of cleaned train dataset is: {len(cleaned_train_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1337ef7e",
   "metadata": {},
   "source": [
    "### Stemming the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c985c2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "re_word = re.compile(r\"^\\w+$\")\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "stem_word: Callable[[str], str] = lambda w : stemmer.stem(w.lower()) if re_word.match(w) else w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5343b09c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bromwel</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>high</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>is</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cartoon</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word  label\n",
       "0  bromwel      1\n",
       "1     high      1\n",
       "2       is      1\n",
       "3        a      1\n",
       "4  cartoon      1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_train_dataset = train_dataset.copy()\n",
    "stemmed_train_dataset['word'] = stemmed_train_dataset['word'].map(stem_word)\n",
    "\n",
    "''' Let's see what stemming does: '''\n",
    "stemmed_train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e2a52e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_test_dataset = test_dataset.copy()\n",
    "stemmed_test_dataset['word'] = stemmed_test_dataset['word'].map(stem_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9769aefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_vocabulary = stemmed_train_dataset['word'].factorize()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d055b1",
   "metadata": {},
   "source": [
    "### Lemmatizing the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0858364",
   "metadata": {},
   "source": [
    "Firstly, we need to download the english model of Spacy lemmatization..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9058f379",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_sm > output_dl.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5be4f63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' loading the small English model '''\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f17affc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 53s, sys: 746 ms, total: 10min 54s\n",
      "Wall time: 10min 55s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bromwell</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>High</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>be</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cartoon</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word  label\n",
       "0  Bromwell      1\n",
       "1      High      1\n",
       "2        be      1\n",
       "3         a      1\n",
       "4   cartoon      1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lemmed_train_dataset = []\n",
    "\n",
    "for entry in imdb['train']:\n",
    "    for token in nlp(entry['text']):\n",
    "        lemmed_train_dataset += [[token.lemma_, entry['label']]]\n",
    "\n",
    "lemmed_train_dataset = pd.DataFrame(lemmed_train_dataset, columns=['word', 'label'])\n",
    "\n",
    "\n",
    "''' Let's see what stemming does: '''\n",
    "lemmed_train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "efe8a27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmed_test_dataset = []\n",
    "\n",
    "for entry in imdb['test']:\n",
    "    for token in nlp(entry['text']):\n",
    "        lemmed_test_dataset += [[token.lemma_, entry['label']]]\n",
    "\n",
    "lemmed_test_dataset = pd.DataFrame(lemmed_test_dataset, columns=['word', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ddba22ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmed_vocabulary = lemmed_train_dataset['word'].factorize()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e4eb60",
   "metadata": {},
   "source": [
    "### Test the model with pre-processing:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6ae1ff",
   "metadata": {},
   "source": [
    "Let's begin with stop word filtered dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "22894489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes_counter is:\n",
      "label\n",
      "0    2605861\n",
      "1    2627419\n",
      "Name: word, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "(cleaned_logprior, cleaned_loglikehood) = train_naive_bayes(cleaned_train_dataset, classes, cleaned_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6d940f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the cleaned train accuracy is about: 0.5814871361746362\n"
     ]
    }
   ],
   "source": [
    "''' Get the best result of each word according to the loglikehood '''\n",
    "cleaned_train_y_pred = np.array([0 if (loglikehood[(0, word)] > loglikehood[(1, word)]) else 1 for word in cleaned_train_dataset['word']])\n",
    "\n",
    "''' Compare to ground truth '''\n",
    "cleaned_train_y_gt = cleaned_train_dataset['label'].to_numpy()\n",
    "\n",
    "cleaned_train_accuracy = (cleaned_train_y_pred == cleaned_train_y_gt).sum() / len(cleaned_train_dataset)\n",
    "print(f\"the cleaned train accuracy is about: {cleaned_train_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "030bdccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the cleaned test accuracy is about: 0.5541434260378817\n"
     ]
    }
   ],
   "source": [
    "''' Get the best result of each word according to the loglikehood '''\n",
    "cleaned_test_y_pred = np.array([0 if (word not in cleaned_vocabulary or loglikehood[(0, word)] > loglikehood[(1, word)]) else 1 for word in cleaned_test_dataset['word']])\n",
    "\n",
    "''' Compare to ground truth '''\n",
    "cleaned_test_y_gt = cleaned_test_dataset['label'].to_numpy()\n",
    "\n",
    "cleaned_test_accuracy = (cleaned_test_y_pred == cleaned_test_y_gt).sum() / len(cleaned_test_dataset)\n",
    "print(f\"the cleaned test accuracy is about: {cleaned_test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd1282a",
   "metadata": {},
   "source": [
    "then with stemming results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eaa0de35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes_counter is:\n",
      "label\n",
      "0    3505555\n",
      "1    3559778\n",
      "Name: word, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "(stemmed_logprior, stemmed_loglikehood) = train_naive_bayes(stemmed_train_dataset, classes, stemmed_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "29252ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the stemmed train accuracy is about: 0.5607646518571736\n"
     ]
    }
   ],
   "source": [
    "''' Get the best result of each word according to the loglikehood '''\n",
    "stemmed_train_y_pred = np.array([0 if (stemmed_loglikehood[(0, word)] > stemmed_loglikehood[(1, word)]) else 1 for word in stemmed_train_dataset['word']])\n",
    "\n",
    "''' Compare to ground truth '''\n",
    "stemmed_train_y_gt = stemmed_train_dataset['label'].to_numpy()\n",
    "\n",
    "stemmed_train_accuracy = (stemmed_train_y_pred == stemmed_train_y_gt).sum() / len(stemmed_train_dataset)\n",
    "print(f\"the stemmed train accuracy is about: {stemmed_train_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "74fdbf32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the stemmed test accuracy is about: 0.5442021425341607\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Get the best result of each word according to the loglikehood\n",
    "we choose the label 0 in case of unknown word (not in vocabulary)\n",
    "'''\n",
    "stemmed_test_y_pred = np.array([0 if (word not in stemmed_vocabulary or stemmed_loglikehood[(0, word)] > stemmed_loglikehood[(1, word)]) else 1 for word in stemmed_test_dataset['word']])\n",
    "\n",
    "''' Compare to ground truth '''\n",
    "stemmed_test_y_gt = stemmed_test_dataset['label'].to_numpy()\n",
    "\n",
    "stemmed_test_accuracy = (stemmed_test_y_pred == stemmed_test_y_gt).sum() / len(stemmed_test_dataset)\n",
    "print(f\"the stemmed test accuracy is about: {stemmed_test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4832fb3",
   "metadata": {},
   "source": [
    "And now the lemmatization results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9cc8ea14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes_counter is:\n",
      "label\n",
      "0    3373917\n",
      "1    3437630\n",
      "Name: word, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "(lemmed_logprior, lemmed_loglikehood) = train_naive_bayes(lemmed_train_dataset, classes, lemmed_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4584f0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the lemmed train accuracy is about: 0.5639915572776639\n"
     ]
    }
   ],
   "source": [
    "''' Get the best result of each word according to the loglikehood '''\n",
    "lemmed_train_y_pred = np.array([0 if (lemmed_loglikehood[(0, word)] > lemmed_loglikehood[(1, word)]) else 1 for word in lemmed_train_dataset['word']])\n",
    "\n",
    "''' Compare to ground truth '''\n",
    "lemmed_train_y_gt = lemmed_train_dataset['label'].to_numpy()\n",
    "\n",
    "lemmed_train_accuracy = (lemmed_train_y_pred == lemmed_train_y_gt).sum() / len(lemmed_train_dataset)\n",
    "print(f\"the lemmed train accuracy is about: {lemmed_train_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eda470f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the lemmed test accuracy is about: 0.5454024420520663\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Get the best result of each word according to the loglikehood\n",
    "we choose the label 0 in case of unknown word (not in vocabulary)\n",
    "'''\n",
    "lemmed_test_y_pred = np.array([0 if (word not in lemmed_vocabulary or lemmed_loglikehood[(0, word)] > lemmed_loglikehood[(1, word)]) else 1 for word in lemmed_test_dataset['word']])\n",
    "\n",
    "''' Compare to ground truth '''\n",
    "lemmed_test_y_gt = lemmed_test_dataset['label'].to_numpy()\n",
    "\n",
    "lemmed_test_accuracy = (lemmed_test_y_pred == lemmed_test_y_gt).sum() / len(lemmed_test_dataset)\n",
    "print(f\"the lemmed test accuracy is about: {lemmed_test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba34ec21",
   "metadata": {},
   "source": [
    "## conclusion about pre-processing:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a81d4d6",
   "metadata": {},
   "source": [
    "We have applied two pre-processing strategies: stemming and lemmatization.\n",
    "Let's make a comparison on accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d70fb870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[30mresults without pre-processing: train [0.567] -- test [0.546]\u001b[0m\n",
      "\u001b[32mresults with stop word filtering: train [0.581] -- test [0.554]\u001b[0m\n",
      "\u001b[31mresults with stemming: \t\ttrain [0.561] -- test [0.544]\u001b[0m\n",
      "results with lemmatization: \ttrain [0.564] -- test [0.545]\n"
     ]
    }
   ],
   "source": [
    "print(colored(f\"results without pre-processing: train [{round(not_preprocessing_train_accuracy, 3)}] -- test [{round(not_preprocessing_test_accuracy, 3)}]\", \"grey\"))\n",
    "print(colored(f\"results with stop word filtering: train [{round(cleaned_train_accuracy, 3)}] -- test [{round(cleaned_test_accuracy, 3)}]\", \"green\"))\n",
    "print(colored(f\"results with stemming: \\t\\ttrain [{round(stemmed_train_accuracy, 3)}] -- test [{round(stemmed_test_accuracy, 3)}]\", \"red\"))\n",
    "print(f\"results with lemmatization: \\ttrain [{round(lemmed_train_accuracy, 3)}] -- test [{round(lemmed_test_accuracy, 3)}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d4f9a7",
   "metadata": {},
   "source": [
    "_Analysis_:\n",
    "\n",
    "Pre-processing doesn't look to be efficient on IMDB dataset __with a Naive Bayes model__.\n",
    "Firstly, It doesn't mean that pre-processing is useless in IMDB dataset. One reason could be that naive bayes results are close to 50%, so the model is slightly better than a randomized predictor. With or without pre-processing will not have a great impact on bad results.\n",
    "\n",
    "However, the act of filtering stop word is pretty efficient because these words are so much represented that they don't give a lot of informations.\n",
    "But we can make such a comparison on our two other strategies. Stemming have the worst result on our benchmark, so the strategy looks to be useless in this case. But lemmatization make better prediction than stemming so maybe it will fit better with IMDB dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc110496",
   "metadata": {},
   "source": [
    "## Build a binary Naive Bayes model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4755289a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_binary_naive_bayes(dataset: DataFrame, classes: list[int], vocabulary: index) -> (list[float], dict[(int, str), float]):\n",
    "    \n",
    "    classes_counter = dataset.groupby('label').count().word\n",
    "    print(f\"classes_counter is:\\n{classes_counter}\")\n",
    "    \n",
    "    loglikehood = {}\n",
    "    logprior = []\n",
    "    \n",
    "\n",
    "    for c in classes:\n",
    "        c_counter = classes_counter[c]\n",
    "        \n",
    "        logprior.append(math.log(c_counter / len(dataset)))\n",
    "       \n",
    "        bag_of_word = dataset[dataset.label == c].word\n",
    "        word_counts = bag_of_word.value_counts()\n",
    "                                                                                     \n",
    "        \n",
    "        \n",
    "        for word in vocabulary:\n",
    "            ''' Here, we just check if the word is present or not '''\n",
    "            count_word_c = word_counts[word] if (word in word_counts) else 0\n",
    "            loglikehood[(c,word)] = 1 if (count_word_c > 0) else 0 # math.log((count_word_c + 1)/(len(bag_of_word) + 1))\n",
    "    \n",
    "    return (logprior, loglikehood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "36a65c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes_counter is:\n",
      "label\n",
      "0    3505555\n",
      "1    3559778\n",
      "Name: word, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "(bin_logprior, bin_loglikehood) = train_binary_naive_bayes(train_dataset, classes, vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c01a67",
   "metadata": {},
   "source": [
    "### Results of binary Naive Bayes model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1ab5df85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the binary model train accuracy is about: 0.5059353890326188\n"
     ]
    }
   ],
   "source": [
    "''' Get the best result of each word according to the loglikehood '''\n",
    "bin_train_y_pred = np.array([0 if (bin_loglikehood[(0, word)] == 1) else 1 for word in train_dataset['word']])\n",
    "\n",
    "''' Compare to ground truth '''\n",
    "bin_train_y_gt = train_dataset['label'].to_numpy()\n",
    "\n",
    "bin_train_accuracy = (bin_train_y_pred == bin_train_y_gt).sum() / len(train_dataset)\n",
    "print(f\"the binary model train accuracy is about: {bin_train_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9c3449a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the binary model test accuracy is about: 0.5017193943748491\n"
     ]
    }
   ],
   "source": [
    "''' Get the best result of each word according to the loglikehood '''\n",
    "bin_test_y_pred = np.array([0 if (word not in vocabulary or bin_loglikehood[(0, word)] == 1) else 1 for word in test_dataset['word']])\n",
    "\n",
    "''' Compare to ground truth '''\n",
    "bin_test_y_gt = test_dataset['label'].to_numpy()\n",
    "\n",
    "bin_test_accuracy = (bin_test_y_pred == bin_test_y_gt).sum() / len(test_dataset)\n",
    "print(f\"the binary model test accuracy is about: {bin_test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ba94aa",
   "metadata": {},
   "source": [
    "## Conclusion:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440d874f",
   "metadata": {},
   "source": [
    "Finally, we have a comparison of two Naive Bayes model with two possible pre-processing strategies. The results show that ...\n",
    "\n",
    "To conclude, let's focus on a wrongly classified set of words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2170294f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4      (cartoon, 0)\n",
       "6            (., 0)\n",
       "9           (at, 0)\n",
       "11        (same, 0)\n",
       "14        (some, 0)\n",
       "17       (about, 0)\n",
       "18      (school, 0)\n",
       "21        (such, 0)\n",
       "23          (``, 0)\n",
       "24    (Teachers, 0)\n",
       "25          ('', 0)\n",
       "26           (., 0)\n",
       "32    (teaching, 0)\n",
       "34        (lead, 0)\n",
       "35          (me, 0)\n",
       "36          (to, 0)\n",
       "37     (believe, 0)\n",
       "38        (that, 0)\n",
       "44        (much, 0)\n",
       "46          (to, 0)\n",
       "Name: word, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_set = train_dataset['word'][train_y_pred != train_y_gt][:20]\n",
    "wrong_set = wrong_set.apply(lambda w : (w, 0 if (loglikehood[(0, w)] > loglikehood[(1, w)]) else 1))\n",
    "wrong_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68d918c",
   "metadata": {},
   "source": [
    "Why does \"cartoon\" is classified as __negative__ ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a8e8b375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the loglikehood of 'cartoon' is:\n",
      "\t0 --> -9.486363387616453\n",
      "\t1 --> -9.68253164037729\n"
     ]
    }
   ],
   "source": [
    "print(f\"the loglikehood of 'cartoon' is:\\n\\t0 --> {loglikehood[(0, 'cartoon')]}\\n\\t1 --> {loglikehood[(1, 'cartoon')]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d423fd",
   "metadata": {},
   "source": [
    "The classification is verified by computing loglikehood, but why \"cartoon\" doesn't seem to be __negative__ ?\n",
    "\n",
    "\"cartoon\" is badly represented in our two labels so counting them will not offer a good interpretation of the feeling behind this word. Moreover, all words that are poorly represented in dataset, or equally divided in our labels will give bad predictions with Naive Bayes models. The reason is because we do not make an interpretation on sentences or context of our words."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
